doc_type,chunk_num,text
sample_project_experience,0,"PROJECT EXPERIENCE Company 1. Capacity Planning project: - The objective was to evaluate the feasibility of running additional freight services after the Cross River Rail becomes operational. - Gathered operational constraints (track load, gauge, etc.) by consulting stakeholders at company to support simulation train service data. - Developed an algorithm to assess the feasibility of rail services by systematically mapping operational constraints, maintenance schedules, and public train timetables. - Procured data from both on-premises and cloud sources, utilizing Databricks for algorithm development and Azure Data Factory for orchestrating ETL jobs. - Created visualizations and communicated insights using Tableau to facilitate decision-making processes. 2. Parking Predictor project - The goal was to build a model predicting the availability of loading zones for delivery drivers across Melbourne based on real-time and historical data. - Analyzed Bluetooth traffic data and parking sensors data, performing historical analysis to understand parking availability in 15-minute intervals, accounting for features like traffic congestion, weather, and school calendar. - Accounted for seasonal variations in parking availability due to peak hours and the time of year. - Used dbt for data modeling with relational data in Postgres and spatial data in ArcGI . Applied Python for feature engineering and"
sample_project_experience,1,"machine learning. - Built 3-dimensional features indexed on temporal and spatial attributes to enhance the model's predictive accuracy. - Delivered a working prototype that led to securing a multi-year project with the client, using Tableau to communicate findings and insights. 3. Supply Chain Risk Predictor project - Phase 1 - The objective was to predict risks in the supply chain using curated financial data from Bloomberg, S&P, and Moody’s, encompassing a network of transactional data between 434 million companies. - Developed a multi-tiered deep network algorithm to identify direct and indirect suppliers within the client’s global supply chain. - Created a batch ingestion pipeline using multi-threading to extract up to 80k news articles daily, which were related to the companies in the extracted supply network. - Used Delta Live Tables in Databricks to store incremental data loads for continuous ingestion. - Categorized risks into four broad categories: Operational, Financial, Reputational, and Environmental. - Developed a machine learning model using natural language processing techniques for feature extraction from news articles, and trained an XGBoost decision-tree classifier for risk categorization. - Conducted interviews and consulting sessions to create in-house assets, such as a word dictionary to capture targeted risks more effectively. 4."
sample_project_experience,2,"Supply Chain Risk Predictor project - Phase 2 - Improved the supply chain network search process by de-duplicating multi-agency datasets and enhancing the search algorithm's speed. - Applied NLP techniques like regex search, cosine similarity, and phonetic distances to identify duplicate records, resulting in the identification of approximately 14 million duplicates. - Trained a semi-supervised machine learning model using manually annotated data to classify company matches based on registered addresses, goods traded, and other characteristics. - Reduced search algorithm processing time by 83% by implementing a graph database in Microsoft SQL Server and optimizing queries using graph elements. - Led a team of three, responsible for sprint management using Azure DevOps, solution design, cloud solution architecture, and graph database implementation. - Used Databricks for compute and pipeline orchestration throughout both project phases. Company 1. GenAI - HR Chatbot Prototype: - Developed an HR chatbot prototype using a Retrieval-Augmented Generation (RAG) pipeline. - Employed various parsing and chunking methodologies to extract text from HR policy documents in PDF format, which were then processed by the text-davinci model for generating text embeddings. - Utilized GPT-4 as the large language model to facilitate interactive chat, incorporating a chat memory mechanism to ensure context"
sample_project_experience,3,"continuity across user sessions. - Successfully streamlined HR-related queries, improving user experience by ensuring responses were contextual and relevant throughout interactions. 2. GenAI - People Survey: - Designed and implemented a system to analyze topic clusters from bi-annual people survey responses. - Developed a concurrent processing module for querying OpenAI APIs, significantly reducing the processing time for handling large volumes of survey data. - Created a module using LangChain for identifying and redacting profane or sensitive information from survey responses, utilizing an iterative chain mechanism for enhanced accuracy. - Conducted statistical analysis to derive actionable insights, which were highly appreciated by C-level executives for providing valuable feedback on improving workplace respect and culture. 3. GenAI - LLM Evaluation: - Led the evaluation of open-source large language models (LLMs) such as Mistral and Dolly for integration into a RAG pipeline designed for the automatic allocation of ServiceNow cases. - Developed a vector index using historical case tickets stored in AWS RDS, the generated index was stored in AWS Redshift and implemented an HNSW space for efficient querying. - Created reusable modules for testing open-source LLMs from Huggingface, using LangChain and custom utilities written in Python within Databricks. - Successfully demonstrated that"
sample_project_experience,4,"some open-source LLMs performed on par with GPT-4 for specific tasks, achieving cost savings of up to 90% compared to proprietary models. 4. Insight Generation - Leader180: - Led a project to identify cultural factors that enhance global leadership capabilities within the organization. - Engaged with stakeholders to understand key areas of focus for leadership and translated these into a structured list of questions for validation through quantitative data collected via a survey of managers and executives. - Applied various statistical tests, including hypothesis testing (parametric and non-parametric), power tests, and more, to extract meaningful insights from the survey data. - Conducted consultations and interviews with stakeholders to discuss the results, and provided strategic recommendations aimed at improving the overall leadership experience for employees. 5. Machine Learning - Attrition: - Developed a machine learning model to predict employee turnover using a variety of multi-agency datasets, including resourcing, compensation, rewards, productivity, and safety data to identify key factors affecting employees' decisions to leave the organization. - Migrated model training and inference jobs from AWS Sagemaker to Databricks to enable end-to-end orchestration and automation of the pipeline. - Implemented MLOps practices using MLflow for monitoring model training, tracking model drift, triggering retraining,"
sample_project_experience,5,"and evaluating models across multiple performance metrics. - Enhanced model performance by refining existing features and creating new dynamic, time-based features representing employment progression history. This was achieved by migrating from reporting data to raw data sourced directly from SAP ERP. - Successfully built ETL pipelines using Delta Live Tables in Databricks to handle incremental data loads, ensuring efficient and reliable data processing. Company 1. Deep learning - Lyric Transcription: - Led the end-to-end delivery of a lyric transcription solution, including model evaluation, productionization, and deployment. - Benchmarked the performance of various open-source Automatic Speech Recognition (ASR) models and stem-splitting techniques using PyTorch, evaluating models from NVIDIA, OpenAI, Meta, and Google to determine the best-performing model for lyric extraction from music files. - Developed a rule-based approach using natural language processing (NLP) techniques to address model hallucination and repetition issues, improving the accuracy and consistency of the transcription output. - Packaged the solution as a Docker image and deployed it using AWS services including Lambda, Elastic Container Registry (ECR), Elastic Container Service (ECS), and SQS queues. - Integrated the solution into the product via an API interface, helping the business achieve competitive parity in AI service offerings. - Built the"
sample_project_experience,6,"solution in a modular fashion, allowing for easy scalability, particularly for GPU-based inference tasks. 2. Deep learning - Key Detection: - Spearheaded the development of a deep-learning model aimed at identifying the overall musical key in audio files. - Conducted literature reviews on state-of-the-art solutions, developed prototypes, and sourced open-source datasets. Collaborated with the legal team to ensure ethical procurement of training datasets. - Successfully applied transfer learning techniques, leveraging pre-trained computer vision classification models on temporal and frequency-based features extracted from audio files, achieving an accuracy rate of 80% in classifying musical keys. - Used PyTorch for model training and implemented advanced deep-learning techniques, such as dynamic data loading, early stopping, and adaptive learning. - Collaborated closely with the product manager and project manager to manage delivery scope and timelines, ensuring the feature was developed on time and aligned with product objectives."
Sample_Resume,0,"Person 041234567 | Australia | s a m p l e e m a i l @ g m a i l . c o m | G i t h u b | L i n k e d i n SUMMARY Person is an experienced Information Science professional in Australia and a Master’s in Data Science, specializing in AI, machine learning, cloud computing, and business intelligence. His expertise includes solution architecture, data modelling, and statistical analysis. Known for successfully managing complex projects, he consistently delivers high-quality results on time, exceeding expectations. CERTIFICATES Databricks ML Associate, Databricks | 12/2023 A.W.S Machine Learning Speciality, Amazon Web Services | 01/2022 Data Security in Healthcare, National Institute of Health | 11/2020 SKILLS Artificial Intelligence Big data (Spark, Hadoop) Business Intelligence (Tableau, PowerBI, Shiny, D3) Programming (Python, R, C++) Computer Vision Cloud (A.W.S, Azure, DataBricks) Data Modelling (SQL, dbt) Deep Learning (Pytorch, Tensorflow) Leadership Machine Learning (Scikit, Xgboost) Natural Language Processing (OpenAI, Huggingface, spacy) Predictive Modelling Project Management (Jira, Confluence, Trello, Azure DevOps) Statistical Analytics Time Series Analytics EDUCATION Master of Data Science, Monash University Melbourne, Australia | 06/2018 - 06/2020 GPA - 3.55/4 Bachelor of Science (Honours) Mathematics, University of Delhi Delhi,"
Sample_Resume,1,"India | 06/2015 - 05/2018 GPA - 8.3/10WORK EXPERIENCE Position, Company Brisbane, Queensland | 04/2024 - 10/2024 Led the end-to-end development and deployment of deep learning solutions aligning technical capabilities with business needs to enhance product offerings. Benchmarked and evaluated open-source Automatic Speech Recognition (ASR) models from NVIDIA, OpenAI, Meta, and Google using PyTorch, resulting in optimized model performance for lyric extraction, directly contributing to achieving competitive AI service parity. Developed a rule-based Natural Language Processing (NLP) system to address hallucination and repetition issues, improving transcription accuracy and enhancing the product's usability. Built and deployed scalable solutions using AWS cloud services (Lambda, ECS, ECR, SQS), enabling efficient and cost-effective inference on GPU-based machines, directly impacting product scalability and performance. Spearheaded the Key Detection feature development using transfer learning on temporal and frequency-based audio features, expanding the product's AI capabilities. Implemented advanced deep learning practices such as dynamic data loading, early stopping, and adaptive learning, improving model robustness and efficiency. Conducted literature reviews and worked with product managers and project managers to align technical delivery with business objectives, ensuring timely feature rollouts that met market demands. Position, Company Brisbane, Queensland | 03/2023 - 04/2024 Developed AI solutions to enhance HR operations"
Sample_Resume,2,"and employee experience, including GPT-4 powered HR chatbot prototype using Retrieval-Augmented Generation (RAG) pipeline, streamlining HR-related queries and improving user engagement. Optimized analysis of bi-annual employee surveys by designing a system for topic clustering and implementing concurrent processing modules with OpenAI APIs, reducing processing time and providing actionable insights to C-level executives on workplace culture and leadership. Evaluated and integrated open-source Large Language Models (LLMs), namely Mistral and Dolly, into RAG pipelines for automating IT System Management (ITSM) case allocations, achieving up to 90% cost savings compared to proprietary models while matching performance. Enhanced predictive analytics for employee attrition by developing machine learning models using multi-agency datasets (resourcing, rewards, productivity, safety), identifying key turnover factors, and migrating workflows to Databricks for end-to-end orchestration and automation. Established MLOps practices using MLflow, monitoring model training, tracking drift, automating retraining processes, and evaluating models across multiple performance metrics to ensure ongoing accuracy and effectiveness. Built efficient ETL pipelines with Delta Live Tables in Databricks, processing incremental data loads from raw SAP based Enterprise Resource Planning (ERP) systems, improving data quality and availability for analytics and reporting. Conducted statistical analyses to inform leadership strategies, applying hypothesis testing and other statistical methods to survey data,"
Sample_Resume,3,"providing strategic recommendations that enhanced leadership experiences and organizational culture. Collaborated with cross-functional stakeholders to align data science initiatives with organizational goals, participated in strategic planning sessions, and supported team by wrangling large datasets using PySpark. Position, Company Brisbane, Queensland | 12/2021 - 03/2023Developed and deployed advanced analytics and machine learning solutions that enhanced clients' operational efficiency and business outcomes. Optimized freight service planning by creating algorithms that mapped operational constraints, maintenance schedules, and timetables, enabling strategic expansion of service capacity. Built predictive models for urban parking availability, analyzing traffic and sensor data to forecast loading zone occupancy, which improved delivery efficiency for clients and led to securing multi-year engagements. Engineered supply chain risk management platforms by developing network algorithms and machine learning models. Processed over 80,000 news articles daily to identify and classify risks, enhancing clients' risk mitigation strategies. Also, enhanced data processing and search algorithms, reducing processing time by 83% through data deduplication and implementing graph database in Microsoft SQL Server, significantly improving search efficiency in large supply chain networks. Led small teams, managing sprint deliveries and overseeing solution design and cloud architecture, ensuring timely execution aligned with client objectives. Transformed large-scale client data into actionable insights through"
Sample_Resume,4,"feature engineering and predictive modeling facilitating data-driven decision-making. Integrated automated data ingestion and processing pipelines from multiple sources—including open-source feeds, APIs, and on-premises systems, ensuring data reliability and availability. Communicated complex technical insights to stakeholders via presentations and interactive dashboards using Tableau, aiding decision-making processes and securing client buy-in. Maintained high standards of MLOps practices, applying agile methodologies, detailed planning, and version control to deliver robust and scalable machine learning solutions. Position, Company Brisbane, Queensland | 11/2020 - 12/2021 Automating data processing pipelines to fuel data-driven research, accelerate internal business processes and reduce product delivery timeline. Developing interactive visualisations and dashboards to deliver risk-analysis reports on Asthma/COPD patients specific to the stakeholder in Primary care. Building and testing clinical NLP models on textual data from secondary care practitioners in Respiratory care. Understanding healthcare functionalities and systems to support decision-making processes in the management. Utilising big data applications to collate and analyse data from multiple sources like Electronic Health Record (EHR), Patient Questionnaires, etc. Position, Company Melbourne, Australia | 03/2020 - 08/2020 Led a team in developing a scalable web application using AGILE methodologies, incorporating geospatial analysis for real-time mapping of koala habitats and bushfires. Designed and implemented ETL pipelines for"
Sample_Resume,5,"cloud-based data storage, processing real-time data on bushfires and smoke direction. Developed a REST API to deliver processed data to the front-end for real-time visualization. Ensured website security with SSL certifications and firewall setup, along with regular maintenance to optimize performance. Position, Company Melbourne, Australia | 01/2020 - 03/2020 Collaborated with two leading scholars from Monash University's Faculty of Information Technology to expand the benchmark Causal Inference Knowledge Base (ATOMIC) by extracting common-sense knowledge from short stories using NLP techniques and training neural network-based models for predictions. Conducted literature reviews on recent advancements in NLP and developed multiple prototype solutions in PyTorch based on this research. VOLUNTEER EXPERIENCE Position, Company Melbourne, Australia | 02/2020 - 03/2020 Led a team of 6 student consultants in devising a new marketing and content strategy through in-depth qualitative and quantitative analysis of survey data. Regularly engaged with stakeholders for requirements gathering and progress updates, delivering recommendations via infographics and dashboards to enhance campaign effectiveness.Position, Company Delhi, India | 09/2016 - 03/2018 Led a team of 150 volunteers addressing blood shortages. Contributed to 26 blood donation camps, collecting 10,000 donations and saving 40,000 lives. Notably, spearheaded the nationally recognized 'Kar Ke Dekho' campaign and managed"
Sample_Resume,6,"partnerships with Uber, Delhi Police, and DUSU for awareness initiatives."
